{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12803740,"sourceType":"datasetVersion","datasetId":8095541}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Required Libraries","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/jacobgil/pytorch-grad-cam.git\n\n\n!pip install lime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:45:05.516373Z","iopub.execute_input":"2025-08-19T06:45:05.516538Z","iopub.status.idle":"2025-08-19T06:46:39.066205Z","shell.execute_reply.started":"2025-08-19T06:45:05.516522Z","shell.execute_reply":"2025-08-19T06:46:39.065233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nfrom torchvision.transforms import ToTensor\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom pytorch_grad_cam import GradCAM, GradCAMPlusPlus, EigenCAM\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\nfrom lime import lime_image\nimport zipfile\nimport os\nfrom tqdm import tqdm ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:47:11.409885Z","iopub.execute_input":"2025-08-19T06:47:11.410192Z","iopub.status.idle":"2025-08-19T06:47:21.696710Z","shell.execute_reply.started":"2025-08-19T06:47:11.410169Z","shell.execute_reply":"2025-08-19T06:47:21.695855Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load and Prepare the Dataset","metadata":{}},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\n\ntransform_train = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ndataset = datasets.ImageFolder(root=\"/kaggle/input/bangladeshi-mango-leaf/Image Dataset of Bangladeshi Mango Leaf/Root/Root/Original\", transform=transform_train)\nclass_names = dataset.classes\nnum_classes = len(class_names)\n\nprint(\"Classes found:\", class_names)\nprint(\"Number of classes:\", num_classes)\n\n\ntrain_size = int(0.7 * len(dataset))\nval_size = int(0.2 * len(dataset))\ntest_size = len(dataset) - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n\nval_dataset.dataset.transform = transform_test\ntest_dataset.dataset.transform = transform_test\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:48:55.009951Z","iopub.execute_input":"2025-08-19T06:48:55.010850Z","iopub.status.idle":"2025-08-19T06:48:56.708983Z","shell.execute_reply.started":"2025-08-19T06:48:55.010820Z","shell.execute_reply":"2025-08-19T06:48:56.708231Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize Example Images for Each Class","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, num_classes, figsize=(15, 5))\ndisplayed_classes = {class_name: False for class_name in class_names}\n\nfor images, labels in train_loader:\n    for img, label in zip(images, labels):\n        class_name = class_names[label]\n        if not displayed_classes[class_name]:\n            img = img.permute(1, 2, 0).numpy()\n            img = (img * 0.5) + 0.5  # unnormalize\n            axs[label].imshow(np.clip(img, 0, 1))\n            axs[label].set_title(class_name)\n            axs[label].axis('off')\n            displayed_classes[class_name] = True\n\n        if all(displayed_classes.values()):\n            break\n    if all(displayed_classes.values()):\n        break\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:49:35.757388Z","iopub.execute_input":"2025-08-19T06:49:35.758114Z","iopub.status.idle":"2025-08-19T06:49:36.595128Z","shell.execute_reply.started":"2025-08-19T06:49:35.758085Z","shell.execute_reply":"2025-08-19T06:49:36.594416Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define a Custom CNN Model ","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n\nclass CustomCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomCNN, self).__init__()\n\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  \n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2),  \n\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),  \n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2),  \n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),  \n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2),  \n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),  \n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d((1, 1))  \n        )\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),  \n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:50:24.264491Z","iopub.execute_input":"2025-08-19T06:50:24.265066Z","iopub.status.idle":"2025-08-19T06:50:24.271506Z","shell.execute_reply.started":"2025-08-19T06:50:24.265011Z","shell.execute_reply":"2025-08-19T06:50:24.270797Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transfer Learning Models","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nfrom torchvision import models\n\ndef get_transfer_model(model_name, num_classes):\n    if model_name == \"vgg16\":\n        model = models.vgg16(pretrained=True)\n        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n\n    elif model_name == \"mobilenet_v2\":\n        model = models.mobilenet_v2(pretrained=True)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n\n    elif model_name == \"efficientnet_b0\":\n        model = models.efficientnet_b0(pretrained=True)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n\n    elif model_name == \"densenet121\":\n        model = models.densenet121(pretrained=True)\n        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n\n    elif model_name == \"inception_v3\":\n        model = models.inception_v3(pretrained=True)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n\n    elif model_name == \"resnet50\":\n        model = models.resnet50(pretrained=True)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)  \n\n    else:\n        raise ValueError(f\"Model '{model_name}' not supported. Choose from vgg16, mobilenet_v2, efficientnet_b0, densenet121, inception_v3, resnet50.\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:51:03.678645Z","iopub.execute_input":"2025-08-19T06:51:03.678946Z","iopub.status.idle":"2025-08-19T06:51:03.685490Z","shell.execute_reply.started":"2025-08-19T06:51:03.678926Z","shell.execute_reply":"2025-08-19T06:51:03.684530Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training and Early Stopping","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n\n    def __init__(self, patience=5):\n\n        self.patience = patience\n        self.counter = 0\n        self.best_loss = np.inf\n\n    def check_early_stop(self, val_loss):\n        if val_loss < self.best_loss:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:51:33.941377Z","iopub.execute_input":"2025-08-19T06:51:33.941676Z","iopub.status.idle":"2025-08-19T06:51:33.946527Z","shell.execute_reply.started":"2025-08-19T06:51:33.941655Z","shell.execute_reply":"2025-08-19T06:51:33.945805Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train the Model and Plot Loss Curves","metadata":{}},{"cell_type":"markdown","source":"# Training using Custom Model (Slow Without AMP)","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nfrom tqdm import tqdm\n\nnum_epochs = 50\n\nmodel = CustomCNN(num_classes=len(class_names)).to('cuda')  \n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nearly_stopping = EarlyStopping(patience=5)\n\ntrain_losses, val_losses = [], []\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    model.train()\n    train_loss = 0\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')  \n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')  \n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:53:06.467441Z","iopub.execute_input":"2025-08-19T06:53:06.468208Z","iopub.status.idle":"2025-08-19T06:54:20.396105Z","shell.execute_reply.started":"2025-08-19T06:53:06.468181Z","shell.execute_reply":"2025-08-19T06:54:20.395375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a path for saving the model\n\nmodel_save_path = \"custom_cnn_model.pth\"  \n\ntorch.save(model.state_dict(), model_save_path)\n\nprint(f\"Model saved to {model_save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:55:14.532061Z","iopub.execute_input":"2025-08-19T06:55:14.532358Z","iopub.status.idle":"2025-08-19T06:55:14.550885Z","shell.execute_reply.started":"2025-08-19T06:55:14.532336Z","shell.execute_reply":"2025-08-19T06:55:14.550065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting loss curves\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:55:35.313832Z","iopub.execute_input":"2025-08-19T06:55:35.314197Z","iopub.status.idle":"2025-08-19T06:55:35.471131Z","shell.execute_reply.started":"2025-08-19T06:55:35.314172Z","shell.execute_reply":"2025-08-19T06:55:35.470523Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Using AMP with Custom Model","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm  \nfrom torch.cuda.amp import autocast, GradScaler  \n\nnum_epochs = 50  \n\nmodel = CustomCNN(num_classes=num_classes).to('cuda')\n\ncriterion = nn.CrossEntropyLoss()  \n\noptimizer = optim.Adam(model.parameters(), lr=0.001)  \n\nearly_stopping = EarlyStopping(patience=5)  \n\ntrain_losses, val_losses = [], []  \n\nscaler = GradScaler()\n\nfor epoch in range(num_epochs):\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    model.train()  \n    train_loss = 0  \n    \n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')  \n        optimizer.zero_grad()  \n        with autocast():  \n            outputs = model(images)  \n            loss = criterion(outputs, labels)  \n\n        scaler.scale(loss).backward()  \n        scaler.step(optimizer)  \n        scaler.update()  \n        train_loss += loss.item()  \n\n    model.eval()  \n    val_loss = 0  \n    with torch.no_grad():  \n        \n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')  \n            with autocast():  \n                outputs = model(images)  \n                loss = criterion(outputs, labels)  \n            val_loss += loss.item()  \n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:56:43.841737Z","iopub.execute_input":"2025-08-19T06:56:43.842495Z","iopub.status.idle":"2025-08-19T06:57:31.655439Z","shell.execute_reply.started":"2025-08-19T06:56:43.842469Z","shell.execute_reply":"2025-08-19T06:57:31.654734Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transfer Learning Example using ResNet50","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm  \nfrom torch.cuda.amp import autocast, GradScaler  \n\nnum_epochs = 50  \n\nmodel = get_transfer_model('resnet50', num_classes).to('cuda')\ncriterion = nn.CrossEntropyLoss()  \n\noptimizer = optim.Adam(model.parameters(), lr=0.001)  \n\nearly_stopping = EarlyStopping(patience=5)  \n\ntrain_losses, val_losses = [], []  \n\nscaler = GradScaler()\n\nfor epoch in range(num_epochs):\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    model.train()  \n    train_loss = 0  \n    \n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')  \n\n        optimizer.zero_grad() \n\n        with autocast():  \n            outputs = model(images)  \n            loss = criterion(outputs, labels)  \n\n        scaler.scale(loss).backward()  \n        scaler.step(optimizer)  \n        scaler.update()  \n        train_loss += loss.item()  \n\n    model.eval()  \n    val_loss = 0  \n    with torch.no_grad():  \n        \n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')  \n            with autocast():  \n                outputs = model(images)  \n                loss = criterion(outputs, labels)  \n            val_loss += loss.item()  \n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break\n\n\n# Save the model\ntorch.save(model.state_dict(), 'transfer_learning_resnet50.pth')\nprint(\"Model saved as 'transfer_learning_resnet50.pth'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T06:58:34.830512Z","iopub.execute_input":"2025-08-19T06:58:34.831323Z","iopub.status.idle":"2025-08-19T06:59:55.779516Z","shell.execute_reply.started":"2025-08-19T06:58:34.831297Z","shell.execute_reply":"2025-08-19T06:59:55.778829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting loss curves\n\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss for ResNet-50\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T07:00:19.501649Z","iopub.execute_input":"2025-08-19T07:00:19.501934Z","iopub.status.idle":"2025-08-19T07:00:19.671311Z","shell.execute_reply.started":"2025-08-19T07:00:19.501912Z","shell.execute_reply":"2025-08-19T07:00:19.670506Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transfer Learning Example using Vgg16","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nfrom torch.amp import autocast, GradScaler  \n\nnum_epochs = 50\n\nmodel = get_transfer_model('vgg16', num_classes).to('cuda')\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nearly_stopping = EarlyStopping(patience=5)\n\ntrain_losses, val_losses = [], []\n\nscaler = GradScaler()\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n\n    model.train()\n    train_loss = 0\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')\n        optimizer.zero_grad()\n\n        with autocast(device_type='cuda'):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        train_loss += loss.item()\n\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')\n            with autocast(device_type='cuda'):\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break\n\n\n# Save model\ntorch.save(model.state_dict(), 'transfer_learning_vgg16.pth')\nprint(\"Model saved as 'transfer_learning_vgg16.pth'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T07:01:37.191370Z","iopub.execute_input":"2025-08-19T07:01:37.192167Z","iopub.status.idle":"2025-08-19T07:06:06.263219Z","shell.execute_reply.started":"2025-08-19T07:01:37.192141Z","shell.execute_reply":"2025-08-19T07:06:06.262557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting loss curves\n\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss for Vgg-16\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T07:06:54.064825Z","iopub.execute_input":"2025-08-19T07:06:54.065348Z","iopub.status.idle":"2025-08-19T07:06:54.237250Z","shell.execute_reply.started":"2025-08-19T07:06:54.065320Z","shell.execute_reply":"2025-08-19T07:06:54.236527Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transfer Learning Example using DenseNet121","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nfrom torch.cuda.amp import autocast, GradScaler\n\nnum_epochs = 50\n\nmodel = get_transfer_model('densenet121', num_classes).to('cuda')\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nearly_stopping = EarlyStopping(patience=5)\n\ntrain_losses, val_losses = [], []\n\nscaler = GradScaler()\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n\n    model.train()\n    train_loss = 0\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')\n        optimizer.zero_grad()\n\n        with autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        train_loss += loss.item()\n\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')\n            with autocast():\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break\n\n\n# Save model\ntorch.save(model.state_dict(), 'transfer_learning_densenet121.pth')\nprint(\"Model saved as 'transfer_learning_densenet121.pth'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T07:07:45.875825Z","iopub.execute_input":"2025-08-19T07:07:45.876673Z","iopub.status.idle":"2025-08-19T07:09:07.204850Z","shell.execute_reply.started":"2025-08-19T07:07:45.876643Z","shell.execute_reply":"2025-08-19T07:09:07.204095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting loss curves\n\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss for DenseNet-121\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T07:09:41.492866Z","iopub.execute_input":"2025-08-19T07:09:41.493199Z","iopub.status.idle":"2025-08-19T07:09:41.648909Z","shell.execute_reply.started":"2025-08-19T07:09:41.493167Z","shell.execute_reply":"2025-08-19T07:09:41.648331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transfer Learning Example using EfficientNet-B0","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nfrom torch.cuda.amp import autocast, GradScaler\n\nnum_epochs = 50\n\nmodel = get_transfer_model('efficientnet_b0', num_classes).to('cuda')\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nearly_stopping = EarlyStopping(patience=5)\n\ntrain_losses, val_losses = [], []\n\nscaler = GradScaler()\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n\n    model.train()\n    train_loss = 0\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')\n        optimizer.zero_grad()\n\n        with autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        train_loss += loss.item()\n\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')\n            with autocast():\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break\n\n# Save model\ntorch.save(model.state_dict(), 'transfer_learning_efficientnet_b0.pth')\nprint(\"Model saved as 'transfer_learning_efficientnet_b0.pth'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T07:11:01.158744Z","iopub.execute_input":"2025-08-19T07:11:01.159067Z","iopub.status.idle":"2025-08-19T07:11:55.314390Z","shell.execute_reply.started":"2025-08-19T07:11:01.159015Z","shell.execute_reply":"2025-08-19T07:11:55.313600Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting loss curves\n\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss for EfficientNet-b0\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T07:12:10.549597Z","iopub.execute_input":"2025-08-19T07:12:10.550320Z","iopub.status.idle":"2025-08-19T07:12:10.720493Z","shell.execute_reply.started":"2025-08-19T07:12:10.550299Z","shell.execute_reply":"2025-08-19T07:12:10.719791Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Evaluation and Metrics Calculation","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nmodel.eval()\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():  \n    for images, labels in test_loader:\n        \n        images, labels = images.to('cuda'), labels.to('cuda')\n\n        outputs = model(images)\n\n        _, predicted = torch.max(outputs, 1)\n\n        all_preds.extend(predicted.cpu().numpy())  \n        all_labels.extend(labels.cpu().numpy())    \n\naccuracy = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds, average='weighted')\nrecall = recall_score(all_labels, all_preds, average='weighted')\nf1 = f1_score(all_labels, all_preds, average='weighted')\n\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T07:12:48.135291Z","iopub.execute_input":"2025-08-19T07:12:48.135572Z","iopub.status.idle":"2025-08-19T07:12:49.245555Z","shell.execute_reply.started":"2025-08-19T07:12:48.135552Z","shell.execute_reply":"2025-08-19T07:12:49.244787Z"}},"outputs":[],"execution_count":null}]}